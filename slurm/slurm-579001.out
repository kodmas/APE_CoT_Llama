Message from TWCC HPC admin
-----------------------
loading miniconda3 with conda 4.8.4/python 3.7
docs : https://hackmd.io/@kmo/twcc_hpc_conda
-----------------------

# conda environments:
#
                         /home/kodmas2023/miniconda3/envs/ape
                         /home/kodmas2023/miniconda3/envs/ape2
base                  *  /opt/ohpc/twcc/conda/4.8.3/miniconda3

/home/kodmas2023/miniconda3/envs/ape/lib/python3.9/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() > 0
[INFO] : Generating prompts from llama2 ...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:40<00:40, 40.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 24.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 26.90s/it]
make_response
ValueError: 'True' is not a valid PaddingStrategy

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/work/kodmas2023/automatic_prompt_engineer/slurm/../experiments/run_instruction_induction.py", line 127, in <module>
    fire.Fire(run)
  File "/home/kodmas2023/miniconda3/envs/ape/lib/python3.9/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/kodmas2023/miniconda3/envs/ape/lib/python3.9/site-packages/fire/core.py", line 475, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/home/kodmas2023/miniconda3/envs/ape/lib/python3.9/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/work/kodmas2023/automatic_prompt_engineer/slurm/../experiments/run_instruction_induction.py", line 63, in run
    res, demo_fn = ape.find_prompts(eval_template=eval_template,
  File "/work/kodmas2023/automatic_prompt_engineer/automatic_prompt_engineer/ape.py", line 170, in find_prompts
    prompts = generate.generate_llama2_prompts(
  File "/work/kodmas2023/automatic_prompt_engineer/automatic_prompt_engineer/generate.py", line 68, in generate_llama2_prompts
    prompts = llama2_model.make_response(queries)
  File "/work/kodmas2023/automatic_prompt_engineer/automatic_prompt_engineer/llm.py", line 102, in make_response
    inputs = self.tokenizer(
  File "/home/kodmas2023/miniconda3/envs/ape/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2798, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/home/kodmas2023/miniconda3/envs/ape/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2884, in _call_one
    return self.batch_encode_plus(
  File "/home/kodmas2023/miniconda3/envs/ape/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 3066, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
  File "/home/kodmas2023/miniconda3/envs/ape/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2640, in _get_padding_truncation_strategies
    padding_strategy = PaddingStrategy(padding)
  File "/home/kodmas2023/miniconda3/envs/ape/lib/python3.9/enum.py", line 384, in __call__
    return cls.__new__(cls, value)
  File "/home/kodmas2023/miniconda3/envs/ape/lib/python3.9/enum.py", line 709, in __new__
    raise exc
  File "/home/kodmas2023/miniconda3/envs/ape/lib/python3.9/enum.py", line 692, in __new__
    result = cls._missing_(value)
  File "/home/kodmas2023/miniconda3/envs/ape/lib/python3.9/site-packages/transformers/utils/generic.py", line 455, in _missing_
    raise ValueError(
ValueError: True is not a valid PaddingStrategy, please select one of ['longest', 'max_length', 'do_not_pad']
