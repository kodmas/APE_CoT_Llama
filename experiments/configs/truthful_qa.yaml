generation:
  num_subsamples: 3
  num_demos: 5
  num_prompts_per_subsample: 30
  model:
    name: Llama2Model
    batch_size: 1
    gpt_config:
      model: text-davinci-002
      temperature: 0.9
      max_tokens: 50
      top_p: 0.9
      top_k: 40
      frequency_penalty: 0.0
      presence_penalty: 0.0
evaluation:
  method: exec_accuracy
  num_samples: 30
  model:
    name: Llama2Model
    batch_size: 1
    gpt_config:
      model: text-davinci-002
      temperature: 0.9
      max_tokens: 200
      top_p: 0.9
      top_k: 40
      frequency_penalty: 0.0
      presence_penalty: 0.0
demo:
  model:
    name: Llama2Model
    batch_size: 1
    gpt_config:
      model: text-davinci-002
      temperature: 0.9
      max_tokens: 200
      top_p: 0.9
      top_k: 40
      frequency_penalty: 0.0
      presence_penalty: 0.0
